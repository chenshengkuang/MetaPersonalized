<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Chensheng Kuang" />

<meta name="date" content="2017-10-17" />

<title>MetaPersonalzied Package Tutorial</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">MetaPersonalzied Package Tutorial</h1>
<h4 class="author"><em>Chensheng Kuang</em></h4>
<h4 class="date"><em>2017-10-17</em></h4>



<p>First, load the package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MetaPersonalized)</code></pre></div>
<p>There is a function built up for the test of the package. We use it to generate some data first. We can supply a seed to the function so it can reproduce simulated data set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim_data =<span class="st"> </span><span class="kw">simulated_dataset</span>(<span class="dt">n =</span> <span class="dv">200</span>, <span class="dt">sim_seed =</span> <span class="dv">123</span>)
<span class="kw">names</span>(sim_data)</code></pre></div>
<pre><code>## [1] &quot;Xlist&quot;   &quot;Ylist&quot;   &quot;Trtlist&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Xlist =<span class="st"> </span>sim_data$Xlist; Ylist =<span class="st"> </span>sim_data$Ylist; Trtlist =<span class="st"> </span>sim_data$Trtlist
<span class="kw">str</span>(Xlist); <span class="kw">str</span>(Ylist); <span class="kw">str</span>(Trtlist)</code></pre></div>
<pre><code>## List of 6
##  $ : num [1:200, 1:50] -0.5605 -0.2302 1.5587 0.0705 0.1293 ...
##  $ : num [1:200, 1:50] 0.508 -0.814 0.275 1.673 -1.314 ...
##  $ : num [1:200, 1:50] -1.7269 0.1708 0.7659 -1.3554 0.0223 ...
##  $ : num [1:200, 1:50] 0.7049 -0.6183 0.1527 -0.0785 0.841 ...
##  $ : num [1:200, 1:50] -1.297 1.843 1.456 -0.244 0.329 ...
##  $ : num [1:200, 1:50] 0.845 -1.968 -1.616 0.474 0.416 ...</code></pre>
<pre><code>## List of 6
##  $ : num [1:200, 1] -7.43 -14.07 2.72 -1.23 8.66 ...
##  $ : num [1:200, 1] 2.29 -10.43 4.69 15.87 -9.59 ...
##  $ : num [1:200, 1] -11.44 -15.98 4.24 -10.18 -7.14 ...
##  $ : num [1:200, 1] -6.67 -6.24 -3.38 1.1 -6.39 ...
##  $ : num [1:200, 1] -1.8 -8.35 28.46 -2.35 -11.48 ...
##  $ : num [1:200, 1] 3.67 -17.7 -9.15 -18.83 -3.01 ...</code></pre>
<pre><code>## List of 6
##  $ : int [1:200] 1 0 0 0 1 0 0 1 1 0 ...
##  $ : int [1:200] 0 1 0 1 1 0 0 0 1 0 ...
##  $ : int [1:200] 0 0 0 0 1 0 1 1 0 1 ...
##  $ : int [1:200] 0 1 1 1 1 0 1 0 0 0 ...
##  $ : int [1:200] 1 1 1 1 0 1 0 1 0 1 ...
##  $ : int [1:200] 1 1 0 0 1 0 1 0 1 1 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Plist =<span class="st"> </span><span class="kw">list</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>)</code></pre></div>
<p>The main functions in this package are <code>MetaPersonalized</code>and <code>MetaPersonalized_cv</code>, where the second is the cross validation version of the first one. The first function will estimate a model for each given penalty parameter while the second will select the optimal one based on cross validation.</p>
<p><code>MetaPersonalized</code> function is based on the below framework: <span class="math display">\[\min_{g_1,\dots,g_K} \sum_{k=1}^K \sum_{i=1}^{n_k}\frac{|\hat{C}_k(X_{i})|}{\sum_{i=1}^{n_k}|\hat{C}_k(X_{i})|}\bigl [1\{\hat{C}_k(X_{i})&gt;0\}-g_k(X_{i})\bigr]^2 + h(g_1,\dots,g_K)\]</span> Here the regularization function <span class="math inline">\(h\)</span> is of the form of a sum of sparse group lasso and fused lasso penalty <span class="math display">\[h = (1-\alpha)\lambda_1\sqrt{q} \sum_{j=1}^p \|\boldsymbol{\beta_j}\|_2+\alpha \lambda_1  \sum_{j=1}^p \|\boldsymbol{\beta_j}\|_1+ \lambda_2 \sum_{j=1}^p \sum_{1\le a &lt; b \le K}|\beta_{ja}-\beta_{jb}|\]</span> where <span class="math inline">\(\boldsymbol{\beta_j}=(\beta_{j1},\dots,\beta_{jK})\)</span>.</p>
<p>When <span class="math inline">\(\lambda_2 = 0\)</span>, the model is implemented through `SGL’ package, and when <span class="math inline">\(\lambda_2 \ne 0\)</span>, the model is implemented through ADMM algorithm.</p>
<p>The function <code>MetaPersonalized</code> offers the following 8 models for separate rules of different studies. They are: “linear”, “lasso”, “GL”, “SGL”, “fused”, “lasso+fused”, “GL+fused” and “SGL+fused”. <code>MetaPersonalized</code> also offers 2 models if we want a unique rule: “linear” and “lasso”. The function <code>MetaPersonalized</code> does not include the “linear” model for both unique rule and separate rule setting.</p>
<p>User should specify a model first and then provide penalty parameter if needed. When fused lasso is included is in the model, user need to specify a sequence <span class="math inline">\(\lambda2\)</span> and <span class="math inline">\(\lambda1\)</span> as well if lasso/GL/SGL is also inclueded. (this will be improved in the future by a computation of default penalty sequence).</p>
<p>Based on the model user selected, the function will warning or stop the running if the necessary penalty parameter is not supplied or unnecessary penalty parameter is supplied.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL =<span class="st"> </span><span class="kw">MetaPersonalized</span>(<span class="dt">Xlist =</span> Xlist, <span class="dt">Ylist =</span> Ylist, <span class="dt">Trtlist =</span> Trtlist,
                             <span class="dt">Plist =</span> Plist, <span class="dt">model =</span> <span class="st">&quot;SGL&quot;</span>, <span class="dt">lambda2 =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>), 
                             <span class="dt">unique_rule =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Warning in MetaPersonalized(Xlist = Xlist, Ylist = Ylist, Trtlist =
## Trtlist, : When model = lasso/GL/SGL, the value for lambda2 is ignored and
## automatically set to be 0!</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL_fused =<span class="st"> </span><span class="kw">MetaPersonalized</span>(<span class="dt">Xlist =</span> Xlist, <span class="dt">Ylist =</span> Ylist, <span class="dt">Trtlist =</span> Trtlist,
                             <span class="dt">Plist =</span> Plist, <span class="dt">model =</span> <span class="st">&quot;SGL+fused&quot;</span>, <span class="dt">lambda2 =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>), 
                             <span class="dt">unique_rule =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Error in MetaPersonalized(Xlist = Xlist, Ylist = Ylist, Trtlist = Trtlist, : When model = lasso+fused/GL+fused/SGL+fused, both values of lambda1 and lambda2 must be supplied!</code></pre>
<p>The model_SGL can still be run but the warning message is good for better usage of the function next time.</p>
<p>The penalty sequence can be withdrawn from the model. For each penalty parameter, a set of coefficients and intercept can be obtained.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(model_SGL)</code></pre></div>
<pre><code>##  [1] &quot;interceptlist&quot;     &quot;betalist&quot;          &quot;lambda1&quot;          
##  [4] &quot;lambda2&quot;           &quot;alpha&quot;             &quot;model&quot;            
##  [7] &quot;unique_rule&quot;       &quot;number_covariates&quot; &quot;number_studies&quot;   
## [10] &quot;Xlist&quot;             &quot;Ylist&quot;             &quot;Trtlist&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL$lambda1 </code></pre></div>
<pre><code>##  [1] 0.24280336 0.21509143 0.19054236 0.16879514 0.14953001 0.13246367
##  [7] 0.11734517 0.10395219 0.09208779 0.08157752 0.07226681 0.06401877
## [13] 0.05671210 0.05023937 0.04450539 0.03942584 0.03492605 0.03093982
## [19] 0.02740856 0.02428034</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL$lambda2</code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#To obtain the beta and intercept for the 10th lambda1</span>
beta =<span class="st"> </span>model_SGL$betalist[[<span class="dv">10</span>]]; intercept =<span class="st"> </span>model_SGL$intercept[[<span class="dv">10</span>]]
<span class="kw">print</span>(beta)</code></pre></div>
<pre><code>##             [,1]       [,2]         [,3]       [,4]       [,5] [,6] [,7]
## [1,] 0.000000000 0.10965671 -0.050499596 0.11602479 0.10215267    0    0
## [2,] 0.003427020 0.12056180 -0.009488525 0.01783210 0.12805898    0    0
## [3,] 0.087490793 0.00000000 -0.124186800 0.04487547 0.06168584    0    0
## [4,] 0.028802683 0.10059312 -0.065296194 0.09933174 0.03961759    0    0
## [5,] 0.002747357 0.11769589 -0.027050519 0.12366812 0.01412283    0    0
## [6,] 0.073453652 0.05650269 -0.120994342 0.02428624 0.03952006    0    0
##      [,8] [,9] [,10]        [,11] [,12] [,13] [,14] [,15] [,16] [,17]
## [1,]    0    0     0  0.000000000     0     0     0     0     0     0
## [2,]    0    0     0  0.000000000     0     0     0     0     0     0
## [3,]    0    0     0 -0.005924263     0     0     0     0     0     0
## [4,]    0    0     0  0.000000000     0     0     0     0     0     0
## [5,]    0    0     0  0.000000000     0     0     0     0     0     0
## [6,]    0    0     0  0.000000000     0     0     0     0     0     0
##      [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] [,27] [,28]
## [1,]     0     0     0     0     0     0     0     0     0     0     0
## [2,]     0     0     0     0     0     0     0     0     0     0     0
## [3,]     0     0     0     0     0     0     0     0     0     0     0
## [4,]     0     0     0     0     0     0     0     0     0     0     0
## [5,]     0     0     0     0     0     0     0     0     0     0     0
## [6,]     0     0     0     0     0     0     0     0     0     0     0
##      [,29] [,30] [,31] [,32] [,33] [,34] [,35]        [,36] [,37] [,38]
## [1,]     0     0     0     0     0     0     0  0.000000000     0     0
## [2,]     0     0     0     0     0     0     0 -0.008193744     0     0
## [3,]     0     0     0     0     0     0     0  0.000000000     0     0
## [4,]     0     0     0     0     0     0     0  0.000000000     0     0
## [5,]     0     0     0     0     0     0     0  0.000000000     0     0
## [6,]     0     0     0     0     0     0     0  0.000000000     0     0
##      [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49]
## [1,]     0     0     0     0     0     0     0     0     0     0     0
## [2,]     0     0     0     0     0     0     0     0     0     0     0
## [3,]     0     0     0     0     0     0     0     0     0     0     0
## [4,]     0     0     0     0     0     0     0     0     0     0     0
## [5,]     0     0     0     0     0     0     0     0     0     0     0
## [6,]     0     0     0     0     0     0     0     0     0     0     0
##      [,50]
## [1,]     0
## [2,]     0
## [3,]     0
## [4,]     0
## [5,]     0
## [6,]     0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(intercept)</code></pre></div>
<pre><code>## [1] 0.4999880 0.6353851 0.6391387 0.6547904 0.6540072 0.6742515</code></pre>
<p>We could also use cross validation to automatically choose the best tuning parameter. Similarly, <code>MetaPersonalized_cv</code> will report an error if the input of penalty parameter does not follow requirements.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL_cv =<span class="st"> </span><span class="kw">MetaPersonalized_cv</span>(<span class="dt">Xlist =</span> Xlist, <span class="dt">Ylist =</span> Ylist, <span class="dt">Trtlist =</span> Trtlist,
                             <span class="dt">Plist =</span> Plist, <span class="dt">model =</span> <span class="st">&quot;SGL&quot;</span>, <span class="dt">lambda2 =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>), 
                             <span class="dt">unique_rule =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Warning in MetaPersonalized_cv(Xlist = Xlist, Ylist = Ylist, Trtlist =
## Trtlist, : When model = lasso/GL/SGL, the value for lambda2 is ignored and
## automatically set to be 0!</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL_fused_cv =<span class="st"> </span><span class="kw">MetaPersonalized_cv</span>(<span class="dt">Xlist =</span> Xlist, <span class="dt">Ylist =</span> Ylist, <span class="dt">Trtlist =</span> Trtlist,
                             <span class="dt">Plist =</span> Plist, <span class="dt">model =</span> <span class="st">&quot;SGL+fused&quot;</span>, <span class="dt">lambda2 =</span> <span class="kw">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>), 
                             <span class="dt">unique_rule =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## Error in MetaPersonalized_cv(Xlist = Xlist, Ylist = Ylist, Trtlist = Trtlist, : When model = lasso+fused/GL+fused/SGL+fused, both values of lambda1 and lambda2 must be supplied!</code></pre>
<p>Different from <code>MetaPersonalized</code>, the output from <code>MetaPersonalzied_cv</code> only has the optimal beta and intercept.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL_cv$lambda1</code></pre></div>
<pre><code>##  [1] 0.24097155 0.21346869 0.18910482 0.16752168 0.14840190 0.13146431
##  [7] 0.11645987 0.10316793 0.09139304 0.08096206 0.07172160 0.06353578
## [13] 0.05628424 0.04986034 0.04416962 0.03912840 0.03466255 0.03070640
## [19] 0.02720178 0.02409715</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL_cv$lambda2</code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL_cv$opt_lambda1</code></pre></div>
<pre><code>## [1] 0.04986034</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL_cv$opt_lambda2</code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL_cv$beta</code></pre></div>
<pre><code>##             [,1]       [,2]        [,3]       [,4]       [,5] [,6]
## [1,] 0.002479505 0.12676489 -0.07580560 0.14202450 0.12509185    0
## [2,] 0.034556444 0.14548358 -0.04658714 0.04303112 0.15407320    0
## [3,] 0.106629020 0.00000000 -0.14039707 0.06073816 0.09462421    0
## [4,] 0.050812029 0.12029202 -0.08983025 0.11405832 0.06834955    0
## [5,] 0.035186324 0.14602938 -0.06487405 0.14373962 0.04167465    0
## [6,] 0.099896896 0.07754872 -0.14524017 0.05093528 0.05237613    0
##               [,7] [,8] [,9]        [,10]       [,11]        [,12] [,13]
## [1,] -0.0159064459    0    0  0.000000000  0.00000000  0.000000000     0
## [2,]  0.0000000000    0    0 -0.001314153  0.00000000  0.000000000     0
## [3,]  0.0000000000    0    0  0.000000000 -0.02857417  0.013510663     0
## [4,]  0.0004949068    0    0  0.000000000  0.00000000 -0.005970391     0
## [5,]  0.0000000000    0    0  0.000000000  0.00000000  0.000000000     0
## [6,]  0.0000000000    0    0  0.000000000  0.00000000  0.000000000     0
##      [,14] [,15]        [,16]        [,17] [,18] [,19] [,20] [,21]
## [1,]     0     0 0.0000000000  0.000000000     0     0     0     0
## [2,]     0     0 0.0000000000 -0.006324487     0     0     0     0
## [3,]     0     0 0.0087453361  0.000000000     0     0     0     0
## [4,]     0     0 0.0195432770  0.000000000     0     0     0     0
## [5,]     0     0 0.0001797252  0.000000000     0     0     0     0
## [6,]     0     0 0.0000000000  0.000000000     0     0     0     0
##            [,22] [,23] [,24]        [,25] [,26] [,27]        [,28] [,29]
## [1,] 0.000000000     0     0  0.000000000     0     0  0.000000000     0
## [2,] 0.000000000     0     0 -0.003731357     0     0  0.003582955     0
## [3,] 0.000000000     0     0  0.002870155     0     0  0.000000000     0
## [4,] 0.000000000     0     0  0.000000000     0     0  0.000000000     0
## [5,] 0.002139362     0     0  0.000000000     0     0  0.000000000     0
## [6,] 0.000000000     0     0  0.000000000     0     0 -0.004861226     0
##      [,30] [,31] [,32] [,33] [,34] [,35]       [,36] [,37] [,38] [,39]
## [1,]     0     0     0     0     0     0  0.00000000     0     0     0
## [2,]     0     0     0     0     0     0 -0.03759733     0     0     0
## [3,]     0     0     0     0     0     0 -0.00444170     0     0     0
## [4,]     0     0     0     0     0     0  0.00000000     0     0     0
## [5,]     0     0     0     0     0     0  0.00000000     0     0     0
## [6,]     0     0     0     0     0     0  0.00000000     0     0     0
##      [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47]        [,48] [,49]
## [1,]     0     0     0     0     0     0     0     0  0.000000000     0
## [2,]     0     0     0     0     0     0     0     0  0.000000000     0
## [3,]     0     0     0     0     0     0     0     0 -0.014828380     0
## [4,]     0     0     0     0     0     0     0     0 -0.001090667     0
## [5,]     0     0     0     0     0     0     0     0  0.000000000     0
## [6,]     0     0     0     0     0     0     0     0  0.000000000     0
##      [,50]
## [1,]     0
## [2,]     0
## [3,]     0
## [4,]     0
## [5,]     0
## [6,]     0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_SGL_cv$intercept</code></pre></div>
<pre><code>## [1] 0.4978597 0.6231527 0.6339489 0.6501677 0.6523319 0.6536596</code></pre>
<p>Besides, we could also try fit a single rule for all the studies.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_unique_lasso_cv =<span class="st"> </span><span class="kw">MetaPersonalized_cv</span>(<span class="dt">Xlist =</span> Xlist, <span class="dt">Ylist =</span> Ylist, <span class="dt">Trtlist =</span> Trtlist,
                                            <span class="dt">Plist =</span> Plist, <span class="dt">model =</span> <span class="st">&quot;lasso&quot;</span>, 
                                            <span class="dt">unique_rule =</span> <span class="ot">TRUE</span>)

model_unique_lasso_cv$unique_lambda</code></pre></div>
<pre><code>##  [1] 1.156491809 1.053752264 0.960139817 0.874843642 0.797124944
##  [6] 0.726310561 0.661787133 0.602995788 0.549427304 0.500617697
## [11] 0.456144200 0.415621607 0.378698929 0.345056360 0.314402504
## [16] 0.286471852 0.261022482 0.237833964 0.216705450 0.197453935
## [21] 0.179912672 0.163929726 0.149366661 0.136097338 0.124006826
## [26] 0.112990401 0.102952645 0.093806616 0.085473095 0.077879901
## [31] 0.070961265 0.064657262 0.058913289 0.053679595 0.048910847
## [36] 0.044565743 0.040606645 0.036999262 0.033712350 0.030717438
## [41] 0.027988585 0.025502156 0.023236615 0.021172338 0.019291446
## [46] 0.017577647 0.016016097 0.014593271 0.013296845 0.012115590
## [51] 0.011039275 0.010058576 0.009165000 0.008350806 0.007608944
## [56] 0.006932986 0.006317079 0.005755887 0.005244550 0.004778638
## [61] 0.004354117 0.003967310 0.003614865 0.003293730 0.003001124
## [66] 0.002734513 0.002491586 0.002270240 0.002068559 0.001884793</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_unique_lasso_cv$opt_unique_lambda</code></pre></div>
<pre><code>## [1] 0.2610225</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_unique_lasso_cv$beta</code></pre></div>
<pre><code>##          V1          V2          V3          V4          V5          V6 
##  0.06149893  0.12138409 -0.10573169  0.10416134  0.09985086  0.00000000 
##          V7          V8          V9         V10         V11         V12 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 
##         V13         V14         V15         V16         V17         V18 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 
##         V19         V20         V21         V22         V23         V24 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 
##         V25         V26         V27         V28         V29         V30 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 
##         V31         V32         V33         V34         V35         V36 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 
##         V37         V38         V39         V40         V41         V42 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 
##         V43         V44         V45         V46         V47         V48 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 
##         V49         V50 
##  0.00000000  0.00000000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_unique_lasso_cv$intercept</code></pre></div>
<pre><code>## [1] 0.6178289</code></pre>
<p>We could use <code>predict</code> function to predict the optimal treatment for new patients. We first generate some new patients. We could specify an overall weighted recommendation rule. The default weight is equal weight for each response/study. For object returned from <code>MetaPersonalized</code> function, <code>predict</code> predicts the benefit score and treatment for each penalty parameter. If we does not supply <code>newx</code>, then <code>predict</code> predicts for the original data for each study based on its own rule.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p =<span class="st"> </span>model_SGL$number_covariates
newx =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(<span class="dv">5</span> *<span class="st"> </span>p), <span class="dt">nrow =</span> <span class="dv">5</span>, <span class="dt">ncol =</span> p)
pred =<span class="st"> </span><span class="kw">predict</span>(model_SGL, <span class="dt">newx =</span> newx, <span class="dt">overall_rec =</span> <span class="ot">TRUE</span>)

<span class="co">#for the 10th penalty parameter</span>
pred$treatment[[<span class="dv">10</span>]]</code></pre></div>
<pre><code>##      Study 1 Study 2 Study 3 Study 4 Study 5 Study 6 Overall Rec
## [1,]       1       1       1       1       1       1           1
## [2,]       0       0       0       0       0       0           0
## [3,]       0       0       1       1       1       1           1
## [4,]       0       1       0       0       0       0           0
## [5,]       1       1       1       1       1       1           1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred$benefit_score[[<span class="dv">10</span>]]</code></pre></div>
<pre><code>##           Study 1   Study 2   Study 3   Study 4   Study 5   Study 6
## [1,]  0.623049312 0.5169320 0.9954471 0.8936321 0.8412727 0.9894766
## [2,] -0.005183257 0.3131189 0.4455506 0.2581069 0.2332710 0.4473476
## [3,]  0.419168166 0.4734180 0.6323312 0.6752627 0.6900546 0.7247752
## [4,]  0.371648033 0.5379992 0.4970184 0.4720180 0.4936998 0.4547490
## [5,]  0.640732055 0.6857506 0.8901478 0.7506479 0.6820430 0.8205834</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_orig =<span class="st"> </span><span class="kw">predict</span>(model_SGL)

<span class="co">#for the 10th penalty parameter</span>
<span class="kw">str</span>(pred_orig$treatment[[<span class="dv">10</span>]])</code></pre></div>
<pre><code>## List of 6
##  $ Study 1: num [1:200, 1] 1 1 1 1 1 1 0 0 1 0 ...
##  $ Study 2: num [1:200, 1] 1 0 1 1 1 1 1 1 1 1 ...
##  $ Study 3: num [1:200, 1] 1 1 1 1 1 1 1 1 1 0 ...
##  $ Study 4: num [1:200, 1] 1 1 1 1 1 1 0 1 1 1 ...
##  $ Study 5: num [1:200, 1] 1 0 1 1 1 1 1 1 1 1 ...
##  $ Study 6: num [1:200, 1] 1 0 1 1 1 1 1 0 1 1 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(pred_orig$benefit_score[[<span class="dv">10</span>]])</code></pre></div>
<pre><code>## List of 6
##  $ Study 1: num [1:200, 1] 0.906 0.633 0.586 0.503 0.541 ...
##  $ Study 2: num [1:200, 1] 0.785 0.457 0.747 0.788 0.511 ...
##  $ Study 3: num [1:200, 1] 0.604 0.782 0.768 0.658 0.68 ...
##  $ Study 4: num [1:200, 1] 0.714 0.516 0.628 0.81 0.546 ...
##  $ Study 5: num [1:200, 1] 0.891 0.391 1.069 0.666 0.902 ...
##  $ Study 6: num [1:200, 1] 0.815 0.236 0.694 0.768 0.604 ...</code></pre>
<p>Similarly, <code>MetaPersonalized_cv</code> gives prediction for the optimal beta and intercept.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_cv =<span class="st"> </span><span class="kw">predict</span>(model_SGL_cv, <span class="dt">newx =</span> newx, <span class="dt">overall_rec =</span> <span class="ot">TRUE</span>)
pred_cv$treatment</code></pre></div>
<pre><code>##      Study 1 Study 2 Study 3 Study 4 Study 5 Study 6 Overall Rec
## [1,]       1       1       1       1       1       1           1
## [2,]       0       0       0       0       0       0           0
## [3,]       0       0       1       1       1       1           1
## [4,]       0       0       0       0       0       0           0
## [5,]       1       1       1       1       1       1           1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_cv$benefit_score</code></pre></div>
<pre><code>##         Study 1   Study 2   Study 3   Study 4   Study 5   Study 6
## [1,]  0.6746364 0.6319058 1.0377822 0.9357422 0.9473359 1.0640031
## [2,] -0.1380395 0.1645472 0.4043644 0.1691036 0.1220357 0.3445454
## [3,]  0.4105100 0.4863711 0.6020686 0.6411679 0.6778313 0.7043192
## [4,]  0.3590037 0.4311650 0.4610941 0.4223243 0.4135480 0.3886623
## [5,]  0.7222361 0.7487553 1.0021924 0.7949585 0.7444460 0.8425796</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_orig_cv =<span class="st"> </span><span class="kw">predict</span>(model_SGL_cv)

<span class="kw">str</span>(pred_orig_cv$treatment)</code></pre></div>
<pre><code>## List of 6
##  $ Study 1: num [1:200, 1] 1 1 1 1 1 1 0 0 1 0 ...
##  $ Study 2: num [1:200, 1] 1 0 1 1 0 1 1 1 1 1 ...
##  $ Study 3: num [1:200, 1] 1 1 1 1 1 1 1 1 0 0 ...
##  $ Study 4: num [1:200, 1] 1 0 1 1 1 1 0 1 1 1 ...
##  $ Study 5: num [1:200, 1] 1 0 1 1 1 1 1 1 1 1 ...
##  $ Study 6: num [1:200, 1] 1 0 1 1 1 1 1 0 0 1 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(pred_orig_cv$benefit_score)</code></pre></div>
<pre><code>## List of 6
##  $ Study 1: num [1:200, 1] 0.968 0.678 0.605 0.51 0.532 ...
##  $ Study 2: num [1:200, 1] 0.76 0.384 0.814 0.857 0.425 ...
##  $ Study 3: num [1:200, 1] 0.527 0.81 0.88 0.642 0.705 ...
##  $ Study 4: num [1:200, 1] 0.698 0.496 0.588 0.867 0.572 ...
##  $ Study 5: num [1:200, 1] 0.943 0.387 1.188 0.662 0.979 ...
##  $ Study 6: num [1:200, 1] 0.8333 0.0964 0.6391 0.7714 0.5525 ...</code></pre>
<p>Last, we introduce <code>plot</code> method for <code>MetaPersonalize</code> and <code>MetaPersonalized_cv</code> output. The <code>plot</code> function draws the mean value of the response based on interaction levels of recommened treatment and received treatment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#to plot for output from MetaPersonalized, we need to supply the index of penalty parameter</span>
<span class="co">#10th of lambda1, 1st of lambda2</span>
<span class="kw">plot</span>(model_SGL, <span class="dt">ind1 =</span> <span class="dv">10</span>, <span class="dt">ind2 =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#plot for output from MetaPersonalized_cv does not need supply the index</span>
<span class="kw">plot</span>(model_SGL_cv)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>This package is now uploaded to Github. Another test.</p>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
